{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4954d826-21ba-4a81-a94e-067c54ec74c4",
   "metadata": {},
   "source": [
    "# Benchmark of available methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d347c2-f33d-43d9-b48a-2253d92fb81e",
   "metadata": {},
   "source": [
    "## Run benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da83537-a443-4b59-b979-0239a25a65e9",
   "metadata": {},
   "source": [
    "To run the benchmark, choose the path of the images to run it on, and the maximum number of samples to use for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a25951-89cb-4165-9359-8f2f22048230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050535cf-4ac3-4f93-b1e8-1bb8d7700304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from robot_vision.recognition import predefined\n",
    "from robot_vision.utils.benchmark import Benchmark\n",
    "\n",
    "predefined.MODELS_FOLDER = '../robot_vision/models'\n",
    "predefined.USER_FACES_FOLDER = '../robot_vision/user_faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f739b974-2cf7-40ac-ae35-f2e583187a17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sample images path: D:/Xavi/DATASETS/FEGA\n",
      "Max. samples: 1000\n"
     ]
    }
   ],
   "source": [
    "sample_imgs_path = input('Sample images path:')\n",
    "max_samples = int(input('Max. samples:'))\n",
    "n_imgs = max_samples if max_samples is not None else len(os.listdir(sample_imgs_path))\n",
    "df = pd.DataFrame(columns=['task','method','img_count','inference_time','inference_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b468c-178f-42c8-bf09-9c25c972a166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for task, methods in predefined.PREDEFINED_RECOGNIZERS.items():\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"       TASK: %s\" % task)\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    for method_name, method in methods.items():\n",
    "        method = method()\n",
    "        b = Benchmark(sample_imgs_path, method, max_samples=max_samples)\n",
    "        b.run()\n",
    "        \n",
    "        print()\n",
    "        print(\"METHOD: %s\" % method_name)\n",
    "        b.print_report()\n",
    "        print()\n",
    "        \n",
    "        new_row = {'task': task, 'method': method_name, 'img_count': n_imgs, 'inference_time': b.get_inference_time(), 'inference_speed': b.get_inference_speed()} \n",
    "        df.loc[len(df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c6cf4-fc98-4c9a-bdb0-6e5b31daaf5d",
   "metadata": {},
   "source": [
    "## Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f6b13e8-bc9b-4f04-a49a-b68f733cd450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>method</th>\n",
       "      <th>img_count</th>\n",
       "      <th>inference_time</th>\n",
       "      <th>inference_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>age_gender</td>\n",
       "      <td>InsightFace</td>\n",
       "      <td>1000</td>\n",
       "      <td>10.900979</td>\n",
       "      <td>91.734882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>age_gender</td>\n",
       "      <td>MiVOLO</td>\n",
       "      <td>1000</td>\n",
       "      <td>92.737771</td>\n",
       "      <td>10.783093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>background_subtraction</td>\n",
       "      <td>RemBG</td>\n",
       "      <td>1000</td>\n",
       "      <td>395.456606</td>\n",
       "      <td>2.528722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>expression</td>\n",
       "      <td>WeiNet</td>\n",
       "      <td>1000</td>\n",
       "      <td>143.973156</td>\n",
       "      <td>6.945739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>expression</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>1000</td>\n",
       "      <td>151.609217</td>\n",
       "      <td>6.595905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>expression</td>\n",
       "      <td>SongNet</td>\n",
       "      <td>1000</td>\n",
       "      <td>157.823802</td>\n",
       "      <td>6.336180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>expression</td>\n",
       "      <td>SilNet</td>\n",
       "      <td>1000</td>\n",
       "      <td>168.922908</td>\n",
       "      <td>5.919860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>expression</td>\n",
       "      <td>Xception</td>\n",
       "      <td>1000</td>\n",
       "      <td>177.965993</td>\n",
       "      <td>5.619051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>expression</td>\n",
       "      <td>MobileNetV3Large</td>\n",
       "      <td>1000</td>\n",
       "      <td>178.723619</td>\n",
       "      <td>5.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>expression</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>1000</td>\n",
       "      <td>200.375394</td>\n",
       "      <td>4.990633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>expression</td>\n",
       "      <td>VGG16</td>\n",
       "      <td>1000</td>\n",
       "      <td>211.852680</td>\n",
       "      <td>4.720261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>expression</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>1000</td>\n",
       "      <td>221.778664</td>\n",
       "      <td>4.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>expression</td>\n",
       "      <td>VGG19</td>\n",
       "      <td>1000</td>\n",
       "      <td>227.643037</td>\n",
       "      <td>4.392842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>expression</td>\n",
       "      <td>ResNet101V2</td>\n",
       "      <td>1000</td>\n",
       "      <td>254.561268</td>\n",
       "      <td>3.928327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>expression</td>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>1000</td>\n",
       "      <td>334.426786</td>\n",
       "      <td>2.990191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face_detection</td>\n",
       "      <td>InsightFace</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.826899</td>\n",
       "      <td>547.375691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face_detection</td>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.694700</td>\n",
       "      <td>85.508817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face_detection</td>\n",
       "      <td>DLIB</td>\n",
       "      <td>1000</td>\n",
       "      <td>125.409641</td>\n",
       "      <td>7.973869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face_detection</td>\n",
       "      <td>ViolaJones</td>\n",
       "      <td>1000</td>\n",
       "      <td>173.878762</td>\n",
       "      <td>5.751134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face_detection</td>\n",
       "      <td>MTCNN</td>\n",
       "      <td>1000</td>\n",
       "      <td>591.473029</td>\n",
       "      <td>1.690694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>face_recognition</td>\n",
       "      <td>InsightFace</td>\n",
       "      <td>1000</td>\n",
       "      <td>63.574172</td>\n",
       "      <td>15.729658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>keypoints</td>\n",
       "      <td>InsightFace</td>\n",
       "      <td>1000</td>\n",
       "      <td>8.138992</td>\n",
       "      <td>122.865340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>keypoints</td>\n",
       "      <td>DLIB</td>\n",
       "      <td>1000</td>\n",
       "      <td>17.581454</td>\n",
       "      <td>56.878118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>keypoints</td>\n",
       "      <td>SPIGA</td>\n",
       "      <td>1000</td>\n",
       "      <td>89.335149</td>\n",
       "      <td>11.193802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>keypoints</td>\n",
       "      <td>ViolaJones</td>\n",
       "      <td>1000</td>\n",
       "      <td>98.118604</td>\n",
       "      <td>10.191747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>keypoints</td>\n",
       "      <td>MTCNN</td>\n",
       "      <td>1000</td>\n",
       "      <td>1226.933913</td>\n",
       "      <td>0.815040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>person_detection</td>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>1000</td>\n",
       "      <td>13.116188</td>\n",
       "      <td>76.241667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      task            method  img_count  inference_time  \\\n",
       "24              age_gender       InsightFace       1000       10.900979   \n",
       "23              age_gender            MiVOLO       1000       92.737771   \n",
       "26  background_subtraction             RemBG       1000      395.456606   \n",
       "14              expression            WeiNet       1000      143.973156   \n",
       "11              expression           AlexNet       1000      151.609217   \n",
       "13              expression           SongNet       1000      157.823802   \n",
       "12              expression            SilNet       1000      168.922908   \n",
       "19              expression          Xception       1000      177.965993   \n",
       "21              expression  MobileNetV3Large       1000      178.723619   \n",
       "22              expression  EfficientNetV2B0       1000      200.375394   \n",
       "17              expression             VGG16       1000      211.852680   \n",
       "15              expression          ResNet50       1000      221.778664   \n",
       "18              expression             VGG19       1000      227.643037   \n",
       "16              expression       ResNet101V2       1000      254.561268   \n",
       "20              expression       InceptionV3       1000      334.426786   \n",
       "1           face_detection       InsightFace       1000        1.826899   \n",
       "0           face_detection            YOLOv8       1000       11.694700   \n",
       "4           face_detection              DLIB       1000      125.409641   \n",
       "3           face_detection        ViolaJones       1000      173.878762   \n",
       "2           face_detection             MTCNN       1000      591.473029   \n",
       "25        face_recognition       InsightFace       1000       63.574172   \n",
       "7                keypoints       InsightFace       1000        8.138992   \n",
       "10               keypoints              DLIB       1000       17.581454   \n",
       "6                keypoints             SPIGA       1000       89.335149   \n",
       "9                keypoints        ViolaJones       1000       98.118604   \n",
       "8                keypoints             MTCNN       1000     1226.933913   \n",
       "5         person_detection            YOLOv8       1000       13.116188   \n",
       "\n",
       "    inference_speed  \n",
       "24        91.734882  \n",
       "23        10.783093  \n",
       "26         2.528722  \n",
       "14         6.945739  \n",
       "11         6.595905  \n",
       "13         6.336180  \n",
       "12         5.919860  \n",
       "19         5.619051  \n",
       "21         5.595231  \n",
       "22         4.990633  \n",
       "17         4.720261  \n",
       "15         4.509000  \n",
       "18         4.392842  \n",
       "16         3.928327  \n",
       "20         2.990191  \n",
       "1        547.375691  \n",
       "0         85.508817  \n",
       "4          7.973869  \n",
       "3          5.751134  \n",
       "2          1.690694  \n",
       "25        15.729658  \n",
       "7        122.865340  \n",
       "10        56.878118  \n",
       "6         11.193802  \n",
       "9         10.191747  \n",
       "8          0.815040  \n",
       "5         76.241667  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df.sort_values(by=['task', 'inference_speed'], ascending=[True, False])\n",
    "sorted_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "age_gender",
   "language": "python",
   "name": "age_gender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
